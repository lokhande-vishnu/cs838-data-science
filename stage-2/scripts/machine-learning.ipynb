{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '0.0' '0.0' ..., 'classic Trinidadian sandwich'\n",
      "  './datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ['0.0' '1.0' '1.0' ..., 'chicken pelau'\n",
      "  './datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ['1.0' '0.0' '0.0' ..., 'blackened fruitcake'\n",
      "  './datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ..., \n",
      " ['0.0' '0.0' '0.0' ..., 'ambience and service'\n",
      "  './datasets/Set_I_DEV/review-285.txt' 'negative']\n",
      " ['0.0' '0.0' '0.0' ..., 'ambience ' './datasets/Set_I_DEV/review-285.txt'\n",
      "  'negative']\n",
      " ['0.0' '0.0' '0.0' ..., 'and service'\n",
      "  './datasets/Set_I_DEV/review-285.txt' 'negative']]\n"
     ]
    }
   ],
   "source": [
    "import arff, numpy as np\n",
    "dataset = arff.load(open('../datasets/features_TRAIN/features_train.arff'))\n",
    "data = np.array(dataset['data'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '0.0' '0.0' ..., '-1' 'true' 'false']\n",
      " ['0.0' '1.0' '1.0' ..., '2' 'false' 'false']\n",
      " ['1.0' '0.0' '0.0' ..., '14' 'false' 'false']\n",
      " ..., \n",
      " ['0.0' '0.0' '0.0' ..., '-1' 'false' 'false']\n",
      " ['0.0' '0.0' '0.0' ..., '-1' 'false' 'false']\n",
      " ['0.0' '0.0' '0.0' ..., '-1' 'false' 'false']]\n"
     ]
    }
   ],
   "source": [
    "length = len(data[0]);\n",
    "data_input = data[:,0:(length-3)]\n",
    "print(data_input)\n",
    "labels = data[:,(length-1)] # this is the class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "labels = np.array([number[0] for number in lb.fit_transform(labels)])\n",
    "print(labels)\n",
    "for i in range(length-3):\n",
    "    data_input[:,i] = le.fit_transform(data_input[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/l/o/lokhande/.local/lib/python3.4/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype <U293 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.96      0.89      6414\n",
      "   positive       0.80      0.46      0.58      2261\n",
      "\n",
      "avg / total       0.83      0.83      0.81      8675\n",
      "\n",
      "Nearest Neighbors\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.68      0.07      0.13      6414\n",
      "   positive       0.26      0.91      0.40      2261\n",
      "\n",
      "avg / total       0.57      0.29      0.20      8675\n",
      "\n",
      "Linear SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.95      0.88      6414\n",
      "   positive       0.75      0.42      0.54      2261\n",
      "\n",
      "avg / total       0.81      0.81      0.79      8675\n",
      "\n",
      "RBF SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.84      0.95      0.89      6414\n",
      "   positive       0.78      0.48      0.59      2261\n",
      "\n",
      "avg / total       0.82      0.83      0.81      8675\n",
      "\n",
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.96      0.89      6414\n",
      "   positive       0.80      0.46      0.58      2261\n",
      "\n",
      "avg / total       0.83      0.83      0.81      8675\n",
      "\n",
      "Neural Net\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.95      0.89      6414\n",
      "   positive       0.75      0.45      0.56      2261\n",
      "\n",
      "avg / total       0.81      0.82      0.80      8675\n",
      "\n",
      "AdaBoost\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.84      0.96      0.89      6414\n",
      "   positive       0.80      0.47      0.59      2261\n",
      "\n",
      "avg / total       0.83      0.83      0.81      8675\n",
      "\n",
      "Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.91      0.87      6414\n",
      "   positive       0.66      0.49      0.56      2261\n",
      "\n",
      "avg / total       0.79      0.80      0.79      8675\n",
      "\n",
      "QDA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.83      0.91      0.87      6414\n",
      "   positive       0.66      0.49      0.56      2261\n",
      "\n",
      "avg / total       0.79      0.80      0.79      8675\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "names = [\"Decision Tree\", \"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=15, max_features=2),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "X, y = (data_input, labels)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #clf.fit(X_train, y_train)\n",
    "    #score = clf.score(X_test, y_test)\n",
    "    print(name)\n",
    "    #print(score)\n",
    "    \n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "    #print(precision)\n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='recall')\n",
    "    #print(precision)\n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "    #print(precision)\n",
    "    y_pred = cross_val_predict(clf,X,y, cv=5)\n",
    "    #for i in range(len(y_pred)):\n",
    "    #    if(y_pred[i] != y[i]):\n",
    "    #        print(data[i][6])\n",
    "    #        print('Actual', y[i])\n",
    "    #        print('Predicted', y_pred[i])\n",
    "    print(classification_report(y, y_pred,target_names = ['negative','positive']))\n",
    "    #print(y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    #if hasattr(clf, \"decision_function\"):\n",
    "    #    Z = clf.decision_function()\n",
    "    #else:\n",
    "    #    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
