{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '0.0' '0.0' ..., 'classic Trinidadian sandwich'\n",
      "  'datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ['0.0' '1.0' '1.0' ..., 'chicken pelau'\n",
      "  'datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ['1.0' '0.0' '0.0' ..., 'blackened fruitcake'\n",
      "  'datasets/Set_I_DEV/review-001.txt' 'positive']\n",
      " ..., \n",
      " ['0.0' '0.0' '0.0' ..., 'in the sort' 'datasets/Set_I_DEV/review-285.txt'\n",
      "  'negative']\n",
      " ['0.0' '0.0' '0.0' ..., 'in ' 'datasets/Set_I_DEV/review-285.txt'\n",
      "  'negative']\n",
      " ['0.0' '0.0' '0.0' ..., 'the sort' 'datasets/Set_I_DEV/review-285.txt'\n",
      "  'negative']]\n"
     ]
    }
   ],
   "source": [
    "import arff, numpy as np\n",
    "dataset = arff.load(open('../datasets/features_I/features_I.arff'))\n",
    "data = np.array(dataset['data'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.0' '0.0' '0.0' ..., '1' '0.0' '0.0']\n",
      " ['0.0' '1.0' '1.0' ..., '0' '0.0' '0.0']\n",
      " ['1.0' '0.0' '0.0' ..., '0' '0.0' '0.0']\n",
      " ..., \n",
      " ['0.0' '0.0' '0.0' ..., '0' '0.0' '0.0']\n",
      " ['0.0' '0.0' '0.0' ..., '0' '0.0' '0.0']\n",
      " ['0.0' '0.0' '0.0' ..., '0' '0.0' '0.0']]\n"
     ]
    }
   ],
   "source": [
    "length = len(data[0]);\n",
    "data_input = data[:,0:(length-3)]\n",
    "print(data_input)\n",
    "labels = data[:,(length-1)] # this is the class column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "labels = np.array([number[0] for number in lb.fit_transform(labels)])\n",
    "print(labels)\n",
    "for i in range(length-3):\n",
    "    data_input[:,i] = le.fit_transform(data_input[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype <U293 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.96      0.92      5160\n",
      "   positive       0.88      0.71      0.79      2266\n",
      "\n",
      "avg / total       0.88      0.88      0.88      7426\n",
      "\n",
      "Random Forest\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.77      0.97      0.86      5160\n",
      "   positive       0.84      0.34      0.48      2266\n",
      "\n",
      "avg / total       0.79      0.78      0.74      7426\n",
      "\n",
      "Nearest Neighbors\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.84      0.40      0.54      5160\n",
      "   positive       0.38      0.82      0.52      2266\n",
      "\n",
      "avg / total       0.70      0.53      0.53      7426\n",
      "\n",
      "Linear SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.85      0.94      0.90      5160\n",
      "   positive       0.83      0.63      0.72      2266\n",
      "\n",
      "avg / total       0.85      0.85      0.84      7426\n",
      "\n",
      "RBF SVM\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.89      0.88      5160\n",
      "   positive       0.74      0.68      0.71      2266\n",
      "\n",
      "avg / total       0.83      0.83      0.83      7426\n",
      "\n",
      "Neural Net\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.86      0.95      0.90      5160\n",
      "   positive       0.84      0.64      0.72      2266\n",
      "\n",
      "avg / total       0.85      0.85      0.85      7426\n",
      "\n",
      "AdaBoost\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.88      0.97      0.92      5160\n",
      "   positive       0.90      0.71      0.79      2266\n",
      "\n",
      "avg / total       0.89      0.89      0.88      7426\n",
      "\n",
      "Naive Bayes\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.82      0.91      0.87      5160\n",
      "   positive       0.74      0.55      0.63      2266\n",
      "\n",
      "avg / total       0.80      0.80      0.80      7426\n",
      "\n",
      "QDA\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.69      1.00      0.82      5160\n",
      "   positive       0.00      0.00      0.00      2266\n",
      "\n",
      "avg / total       0.48      0.69      0.57      7426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:695: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: divide by zero encountered in power\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:719: RuntimeWarning: invalid value encountered in multiply\n",
      "  X2 = np.dot(Xm, R * (S ** (-0.5)))\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:722: RuntimeWarning: divide by zero encountered in log\n",
      "  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "names = [\"Decision Tree\", \"Random Forest\", \"Nearest Neighbors\",\n",
    "         \"Linear SVM\", \"RBF SVM\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"QDA\"]\n",
    "\n",
    "classifiers = [\n",
    "    DecisionTreeClassifier(max_depth=7),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "# preprocess dataset, split into training and test part\n",
    "X, y = (data_input, labels)\n",
    "X = StandardScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "# iterate over classifiers\n",
    "for name, clf in zip(names, classifiers):\n",
    "    #clf.fit(X_train, y_train)\n",
    "    #score = clf.score(X_test, y_test)\n",
    "    print(name)\n",
    "    #print(score)\n",
    "    \n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "    #print(precision)\n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='recall')\n",
    "    #print(precision)\n",
    "    #precision = cross_val_score(clf, X, y, cv=5, scoring='f1')\n",
    "    #print(precision)\n",
    "    y_pred = cross_val_predict(clf,X,y, cv=5)\n",
    "    #for i in range(len(y_pred)):\n",
    "    #    if(y_pred[i] != y[i]):\n",
    "    #        print(data[i][6])\n",
    "    #        print('Actual', y[i])\n",
    "    #        print('Predicted', y_pred[i])\n",
    "    print(classification_report(y, y_pred,target_names = ['negative','positive']))\n",
    "    #print(y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    #if hasattr(clf, \"decision_function\"):\n",
    "    #    Z = clf.decision_function()\n",
    "    #else:\n",
    "    #    Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
